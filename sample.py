import tensorflow as tf
import numpy as np

def sample(sess,model,vocab,chars,init_word='',random=True,num=200):
  '''
  Method to sample the LSTM and generates sentences
  :param sess: tf session for the sampling
  :param model: tf model to be used
  :param vocab: dictionary for converting the characters into internal representations
  :param init_word: starting word for the sampling
  :param random: do you want to generate words based on max probability or random choosen probability
  :param num: number of characters you want to generate
  :return: text generated by the model
  '''

  # the idea is to basically propagate the characters generated into the LSTM state
  # get its output and put them back in again
  state = model.initial_state.eval()
  prediction = tf.zeros([1,len(vocab)])


  # seeding the LSTM
  if len(init_word) >0:
    print "Seeding with " + str(init_word)
    for c in init_word:
      ip = vocab[c]
      x = tf.zeros([1,1])
      x[0,0] = ip
      [state, prediction] = sess.run([model.final_state, model.output_prob],
                         feed_dict={model.input_layer: x, model.initial_state: state})
  else:
    print "Seeding with equal probabilities"
    # note the current state still remains zero, as per Karpathy's implementation
    prediction = tf.random_uniform([1,len(vocab)])

  # start sampling
  ret = init_word
  for i in range(num):

    # based on the initial words prime the input to the LSTM
    if not random:
      sample = np.argmax(prediction)
    else:
      sample = np.random.multinomial(1,prediction)

    pred_char = chars(sample)
    ret += pred_char

    x = tf.zeros([1,1])
    x[0,0] = sample
    [state, prediction] = sess.run([model.final_state, model.output_prob],
                       feed_dict={model.input_layer: x, model.initial_state: state})

def main():
  raise NotImplementedError

if __name__ == '__main__':
  main()